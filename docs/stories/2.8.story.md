# Story 2.8: JSON Schema Test Suite Compliance

## Status

**Approved**

## Story

**As a** developer,
**I want** the validator to pass the official JSON Schema Test Suite,
**so that** I have confidence in specification compliance.

## Acceptance Criteria

1. JSON Schema Test Suite Draft 7 tests downloaded/integrated into test structure
2. Test runner class executes all Draft 7 test files
3. Test results report shows pass/fail count per test file
4. All core vocabulary tests pass (type, enum, const, properties, items, etc.)
5. All combinator tests pass (allOf, anyOf, oneOf, not)
6. All conditional tests pass (if/then/else, dependencies)
7. All reference tests pass ($ref, definitions)
8. Optional format tests documented (pass/fail acceptable per spec)
9. Any failing tests documented with explanation (spec interpretation differences)
10. Test suite can be re-run as regression test
11. Compliance report generated showing overall pass rate (target: 100% required, optional documented)

## Tasks / Subtasks

- [ ] **Task 1: Download and Integrate JSON Schema Test Suite** (AC: 1)
  - [ ] Create directory structure: `test-suite/draft7/`
  - [ ] Download JSON Schema Test Suite from GitHub: `https://github.com/json-schema-org/JSON-Schema-Test-Suite`
  - [ ] Copy Draft 7 tests from `tests/draft7/` directory
  - [ ] Document included test files in a manifest
  - [ ] Add test-suite directory to .gitignore OR commit test files (team decision)

- [ ] **Task 2: Create TestSuiteRunner.cls Base Class** (AC: 2, 3, 10)
  - [ ] Create file: `src/Test/JSONSchema/TestSuite/TestSuiteRunner.cls`
  - [ ] Implement `RunAllTests() As %Status` - main entry point
  - [ ] Implement `LoadTestFile(pFilePath As %String) As %DynamicArray` - parse JSON test file
  - [ ] Implement `ExecuteTestGroup(pGroup As %DynamicObject) As %Boolean` - run test group
  - [ ] Implement `ExecuteSingleTest(pTest As %DynamicObject, pSchema As %DynamicObject) As %Boolean`
  - [ ] Implement result tracking: pass count, fail count, skip count per file
  - [ ] Implement `GenerateReport() As %String` - create summary report
  - [ ] Compile using MCP tool `compile_objectscript_class`

- [ ] **Task 3: Implement Test File Discovery** (AC: 1, 2)
  - [ ] Implement `GetTestFiles() As %DynamicArray` - list all .json test files
  - [ ] Support filtering by category (optional, core, format)
  - [ ] Support running individual test files by name
  - [ ] Support running specific test groups within a file

- [ ] **Task 4: Create Core Vocabulary Test Execution** (AC: 4)
  - [ ] Create file: `src/Test/JSONSchema/TestSuite/TestCoreVocabulary.cls`
  - [ ] Run tests for: type.json, enum.json, const.json
  - [ ] Run tests for: properties.json, additionalProperties.json, required.json
  - [ ] Run tests for: items.json, additionalItems.json
  - [ ] Run tests for: minLength.json, maxLength.json, pattern.json
  - [ ] Run tests for: minimum.json, maximum.json, exclusiveMinimum.json, exclusiveMaximum.json
  - [ ] Run tests for: minItems.json, maxItems.json, uniqueItems.json, contains.json
  - [ ] Run tests for: minProperties.json, maxProperties.json, propertyNames.json
  - [ ] Compile using MCP tool `compile_objectscript_class`

- [ ] **Task 5: Create Combinator Test Execution** (AC: 5)
  - [ ] Create file: `src/Test/JSONSchema/TestSuite/TestCombinators.cls`
  - [ ] Run tests for: allOf.json
  - [ ] Run tests for: anyOf.json
  - [ ] Run tests for: oneOf.json
  - [ ] Run tests for: not.json
  - [ ] Compile using MCP tool `compile_objectscript_class`

- [ ] **Task 6: Create Conditional Test Execution** (AC: 6)
  - [ ] Create file: `src/Test/JSONSchema/TestSuite/TestConditionals.cls`
  - [ ] Run tests for: if-then-else.json
  - [ ] Run tests for: dependencies.json
  - [ ] Compile using MCP tool `compile_objectscript_class`

- [ ] **Task 7: Create Reference Test Execution** (AC: 7)
  - [ ] Create file: `src/Test/JSONSchema/TestSuite/TestReferences.cls`
  - [ ] Run tests for: ref.json
  - [ ] Run tests for: definitions.json (if separate file exists)
  - [ ] Handle remote $ref tests (use cache pre-population or skip with documentation)
  - [ ] Compile using MCP tool `compile_objectscript_class`

- [ ] **Task 8: Handle Optional Format Tests** (AC: 8)
  - [ ] Create file: `src/Test/JSONSchema/TestSuite/TestFormats.cls`
  - [ ] Run tests for: optional/format/*.json files
  - [ ] Mark format tests as optional in results (pass/fail acceptable)
  - [ ] Document which formats are supported vs unsupported
  - [ ] Compile using MCP tool `compile_objectscript_class`

- [ ] **Task 9: Implement Failure Documentation** (AC: 9)
  - [ ] Create failure tracking with test file, group, and test name
  - [ ] Capture expected vs actual result for each failure
  - [ ] Add explanation field for known spec interpretation differences
  - [ ] Create `SkipList` for intentionally skipped tests with rationale

- [ ] **Task 10: Create Compliance Report Generator** (AC: 11)
  - [ ] Implement `GenerateComplianceReport() As %String`
  - [ ] Show overall pass rate percentage
  - [ ] Break down by category (core, combinators, conditionals, refs, format)
  - [ ] List all failures with explanations
  - [ ] Output to console and optionally to file
  - [ ] Include timestamp and validator version

- [ ] **Task 11: Create Unit Test Wrapper** (AC: 10)
  - [ ] Create `src/Test/JSONSchema/TestSuiteCompliance.cls` extending %UnitTest.TestCase
  - [ ] Implement `TestCoreVocabularyCompliance()` - assert core tests pass
  - [ ] Implement `TestCombinatorCompliance()` - assert combinator tests pass
  - [ ] Implement `TestConditionalCompliance()` - assert conditional tests pass
  - [ ] Implement `TestReferenceCompliance()` - assert reference tests pass
  - [ ] Implement `TestOverallCompliance()` - assert 100% required tests pass
  - [ ] Compile using MCP tool `compile_objectscript_class`

- [ ] **Task 12: Run Full Test Suite and Document Results** (AC: 3, 4, 5, 6, 7, 8, 9, 11)
  - [ ] Execute full test suite via MCP tool
  - [ ] Document pass/fail counts per category
  - [ ] Fix any failing tests in validator implementation
  - [ ] Document any unfixable failures with rationale
  - [ ] Verify all 290+ existing unit tests still pass
  - [ ] Generate final compliance report

## Dev Notes

### Previous Story Insights
[Source: docs/stories/2.7.story.md - Dev Agent Record]

**Key learnings from Story 2.7 (Schema References):**
1. **Counter-based circular detection** works well for distinguishing recursive schemas from true circular references
2. **Remote schema caching** via Context.RemoteSchemaCache - can pre-populate for testing
3. **All 290 tests currently passing** - Epic 1 (1.1-1.6) + Epic 2 (2.1-2.7)
4. **Validator.cls** has $ref handling at start of both ValidateNode() and ValidateNodeWithType()

### JSON Schema Test Suite Structure
[Source: https://github.com/json-schema-org/JSON-Schema-Test-Suite]

**Repository Structure:**
```
JSON-Schema-Test-Suite/
├── tests/
│   ├── draft7/                    # Draft 7 tests (our target)
│   │   ├── type.json
│   │   ├── enum.json
│   │   ├── const.json
│   │   ├── properties.json
│   │   ├── additionalProperties.json
│   │   ├── required.json
│   │   ├── items.json
│   │   ├── additionalItems.json
│   │   ├── allOf.json
│   │   ├── anyOf.json
│   │   ├── oneOf.json
│   │   ├── not.json
│   │   ├── if-then-else.json
│   │   ├── dependencies.json
│   │   ├── ref.json
│   │   ├── definitions.json
│   │   ├── ... (more files)
│   │   └── optional/
│   │       └── format/
│   │           ├── date-time.json
│   │           ├── email.json
│   │           ├── uri.json
│   │           └── ... (more format files)
│   ├── draft2019-09/
│   └── draft2020-12/
└── remotes/                       # Remote schemas for $ref tests
```

**Test File Format (JSON):**
```json
[
  {
    "description": "object type matches objects",
    "schema": {"type": "object"},
    "tests": [
      {
        "description": "an object is an object",
        "data": {},
        "valid": true
      },
      {
        "description": "an array is not an object",
        "data": [],
        "valid": false
      }
    ]
  }
]
```

### Project Structure for Test Suite
[Source: architecture/10-project-structure.md]

**Proposed Structure:**
```
src/Test/JSONSchema/
├── TestSuite/                     # NEW - Test Suite Runner
│   ├── TestSuiteRunner.cls        # Main runner class
│   ├── TestCoreVocabulary.cls     # Core vocabulary tests
│   ├── TestCombinators.cls        # Combinator tests
│   ├── TestConditionals.cls       # Conditional tests
│   ├── TestReferences.cls         # Reference tests
│   └── TestFormats.cls            # Optional format tests
├── TestSuiteCompliance.cls        # NEW - %UnitTest wrapper
├── TestValidator.cls              # Existing
├── TestTypeValidation.cls         # Existing
├── TestEnumConst.cls              # Existing
├── ... (other existing tests)
└── TestRefKeyword.cls             # Existing (Story 2.7)

test-suite/                        # NEW - Test Suite Data
└── draft7/                        # Draft 7 test files
    ├── type.json
    ├── enum.json
    └── ... (test files)
```

### Test Runner Implementation Pattern
[Source: architecture/15-coding-standards.md]

**TestSuiteRunner Class Template:**
```objectscript
/// Test.JSONSchema.TestSuite.TestSuiteRunner - JSON Schema Test Suite Runner
/// <p>
/// Executes the official JSON Schema Test Suite and generates compliance reports.
/// </p>
Class Test.JSONSchema.TestSuite.TestSuiteRunner Extends %RegisteredObject
{

Property TestSuiteDir As %String;
Property PassCount As %Integer [ InitialExpression = 0 ];
Property FailCount As %Integer [ InitialExpression = 0 ];
Property SkipCount As %Integer [ InitialExpression = 0 ];
Property Results As %DynamicArray;
Property SkipList As %DynamicObject;

Method %OnNew(pTestSuiteDir As %String = "") As %Status
{
    If pTestSuiteDir = "" {
        // Default location relative to installation
        Set ..TestSuiteDir = "test-suite/draft7"
    } Else {
        Set ..TestSuiteDir = pTestSuiteDir
    }
    Set ..Results = ##class(%DynamicArray).%New()
    Set ..SkipList = ##class(%DynamicObject).%New()
    Quit $$$OK
}

/// Run all tests in the test suite
Method RunAllTests() As %Status
{
    Set tSC = $$$OK
    Try {
        Set tFiles = ..GetTestFiles()
        Set tIter = tFiles.%GetIterator()
        While tIter.%GetNext(.tIdx, .tFile) {
            Do ..RunTestFile(tFile)
        }
        Quit
    }
    Catch ex {
        Set tSC = ex.AsStatus()
    }
    Quit tSC
}

/// Run tests from a single test file
Method RunTestFile(pFileName As %String) As %Boolean
{
    Set tAllPassed = 1
    Try {
        Set tFilePath = ..TestSuiteDir _ "/" _ pFileName
        Set tTestGroups = ..LoadTestFile(tFilePath)
        
        Set tIter = tTestGroups.%GetIterator()
        While tIter.%GetNext(.tIdx, .tGroup) {
            Set tGroupPassed = ..ExecuteTestGroup(tGroup, pFileName)
            If 'tGroupPassed Set tAllPassed = 0
        }
        Quit
    }
    Catch ex {
        Set tAllPassed = 0
    }
    Quit tAllPassed
}

/// Load and parse a test file
Method LoadTestFile(pFilePath As %String) As %DynamicArray
{
    Set tResult = ##class(%DynamicArray).%New()
    Try {
        Set tStream = ##class(%Stream.FileCharacter).%New()
        Set tSC = tStream.LinkToFile(pFilePath)
        If $$$ISERR(tSC) Quit
        
        Set tJSON = tStream.Read()
        Set tResult = ##class(%DynamicAbstractObject).%FromJSON(tJSON)
        Quit
    }
    Catch ex {
        // Return empty array on error
    }
    Quit tResult
}

/// Execute a test group (schema + multiple tests)
Method ExecuteTestGroup(pGroup As %DynamicObject, pFileName As %String) As %Boolean
{
    Set tAllPassed = 1
    Try {
        Set tSchema = pGroup.schema
        Set tGroupDesc = pGroup.description
        Set tTests = pGroup.tests
        
        Set tIter = tTests.%GetIterator()
        While tIter.%GetNext(.tIdx, .tTest) {
            Set tTestPassed = ..ExecuteSingleTest(tTest, tSchema, pFileName, tGroupDesc)
            If 'tTestPassed Set tAllPassed = 0
        }
        Quit
    }
    Catch ex {
        Set tAllPassed = 0
    }
    Quit tAllPassed
}

/// Execute a single test case
Method ExecuteSingleTest(pTest As %DynamicObject, pSchema As %DynamicObject, pFileName As %String, pGroupDesc As %String) As %Boolean
{
    Set tPassed = 0
    Try {
        Set tData = pTest.data
        Set tExpectedValid = pTest.valid
        Set tTestDesc = pTest.description
        
        // Run validation
        Set tActualValid = ##class(JSONSchema.Validator).Validate(tData, pSchema, .tErrors)
        
        // Compare result
        Set tPassed = (tActualValid = tExpectedValid)
        
        If tPassed {
            Set ..PassCount = ..PassCount + 1
        } Else {
            Set ..FailCount = ..FailCount + 1
            // Record failure
            Set tFailure = {
                "file": (pFileName),
                "group": (pGroupDesc),
                "test": (tTestDesc),
                "expected": (tExpectedValid),
                "actual": (tActualValid)
            }
            Do ..Results.%Push(tFailure)
        }
        Quit
    }
    Catch ex {
        Set ..FailCount = ..FailCount + 1
        Set tPassed = 0
    }
    Quit tPassed
}

/// Generate compliance report
Method GenerateReport() As %String
{
    Set tReport = ""
    Set tTotal = ..PassCount + ..FailCount + ..SkipCount
    Set tPassRate = $Select(tTotal>0: (..PassCount / tTotal) * 100, 1: 0)
    
    Set tReport = tReport _ "================================" _ $C(13,10)
    Set tReport = tReport _ "JSON Schema Test Suite Report" _ $C(13,10)
    Set tReport = tReport _ "================================" _ $C(13,10)
    Set tReport = tReport _ "Total Tests: " _ tTotal _ $C(13,10)
    Set tReport = tReport _ "Passed: " _ ..PassCount _ $C(13,10)
    Set tReport = tReport _ "Failed: " _ ..FailCount _ $C(13,10)
    Set tReport = tReport _ "Skipped: " _ ..SkipCount _ $C(13,10)
    Set tReport = tReport _ "Pass Rate: " _ $FNumber(tPassRate, "", 2) _ "%" _ $C(13,10)
    Set tReport = tReport _ "================================" _ $C(13,10)
    
    // List failures
    If ..Results.%Size() > 0 {
        Set tReport = tReport _ $C(13,10) _ "FAILURES:" _ $C(13,10)
        Set tIter = ..Results.%GetIterator()
        While tIter.%GetNext(.tIdx, .tFailure) {
            Set tReport = tReport _ "- " _ tFailure.file _ ": " _ tFailure.group _ " / " _ tFailure.test _ $C(13,10)
            Set tReport = tReport _ "  Expected: " _ tFailure.expected _ ", Actual: " _ tFailure.actual _ $C(13,10)
        }
    }
    
    Quit tReport
}

}
```

### File Reading in ObjectScript
[Source: InterSystems Documentation]

**Reading JSON Files from Filesystem:**
```objectscript
/// Read a JSON file from the filesystem
ClassMethod ReadJSONFile(pFilePath As %String) As %DynamicAbstractObject
{
    Set tResult = ""
    Try {
        Set tStream = ##class(%Stream.FileCharacter).%New()
        Set tSC = tStream.LinkToFile(pFilePath)
        If $$$ISERR(tSC) {
            Throw ##class(%Exception.StatusException).CreateFromStatus(tSC)
        }
        
        Set tJSON = ""
        While 'tStream.AtEnd {
            Set tJSON = tJSON _ tStream.Read()
        }
        
        Set tResult = ##class(%DynamicAbstractObject).%FromJSON(tJSON)
        Quit
    }
    Catch ex {
        Throw ex
    }
    Quit tResult
}
```

**Directory Listing:**
```objectscript
/// Get list of .json files in a directory
ClassMethod GetJSONFiles(pDirectory As %String) As %DynamicArray
{
    Set tFiles = ##class(%DynamicArray).%New()
    
    Set tRS = ##class(%ResultSet).%New("%Library.File:FileSet")
    Do tRS.Execute(pDirectory, "*.json")
    
    While tRS.Next() {
        Set tFileName = tRS.Get("Name")
        Do tFiles.%Push(tFileName)
    }
    
    Quit tFiles
}
```

### Remote Reference Handling Strategy
[Source: docs/stories/2.7.story.md - Dev Notes]

**For Remote $ref Tests:**
The official test suite uses `localhost:1234` with a local `remotes/` folder. Options:
1. **Pre-populate cache** (Recommended): Load remotes/ folder schemas into Context.RemoteSchemaCache before running tests
2. **Skip with documentation**: Mark remote tests as skipped with explanation
3. **Mock HTTP**: Create a mock %Net.HttpRequest for testing

**Cache Pre-population Pattern:**
```objectscript
// Load remote schemas before running ref tests
Set tContext = ##class(JSONSchema.Context).%New()
Set tRemoteSchema = ..ReadJSONFile("test-suite/remotes/integer.json")
Do tContext.RemoteSchemaCache.%Set("http://localhost:1234/integer.json", tRemoteSchema)
```

### Known Test Suite Edge Cases
[Source: JSON Schema Test Suite documentation, community discussions]

**Tests That May Need Special Handling:**
1. **Remote $ref tests** - Require remotes/ folder or cache pre-population
2. **Format tests** - Optional per spec; document supported vs unsupported formats
3. **Big number tests** - ObjectScript numeric precision limits
4. **Unicode edge cases** - Ensure proper character handling
5. **Recursive $ref** - Already handled with counter-based detection (Story 2.7)

### Tech Stack Summary
[Source: architecture/3-tech-stack.md]

| Component | Technology | Version | Purpose |
|-----------|------------|---------|---------|
| Test Framework | %UnitTest.TestCase | Native | Unit test wrapper |
| File I/O | %Stream.FileCharacter | Native | Read JSON test files |
| JSON Parsing | %DynamicAbstractObject | Native | Parse test files |
| Directory Listing | %Library.File:FileSet | Native | List test files |
| Validator | JSONSchema.Validator | Local | Schema validation |
| Context | JSONSchema.Context | Local | Validation context |

## Testing

### Test File Location
- `src/Test/JSONSchema/TestSuite/*.cls` (NEW - Test Suite Runner classes)
- `src/Test/JSONSchema/TestSuiteCompliance.cls` (NEW - %UnitTest wrapper)

### Testing Standards
- Use `%UnitTest.TestCase` framework for wrapper tests
- TestSuiteRunner can be run standalone or via %UnitTest wrapper
- All test methods must return `%Status` (return `$$$OK`)
- Use `$$$AssertTrue()`, `$$$AssertEquals()` macros
- Triple dollar signs ($$$) required for all macros
- Maximum 800 lines per test file

### Test Method Patterns
```objectscript
/// Test that core vocabulary tests all pass
Method TestCoreVocabularyCompliance() As %Status
{
    Set tRunner = ##class(Test.JSONSchema.TestSuite.TestSuiteRunner).%New()
    
    // Run core vocabulary tests
    Do tRunner.RunTestFile("type.json")
    Do tRunner.RunTestFile("enum.json")
    Do tRunner.RunTestFile("const.json")
    Do tRunner.RunTestFile("properties.json")
    // ... more files
    
    // Assert 100% pass rate for core vocabulary
    Set tTotal = tRunner.PassCount + tRunner.FailCount
    Set tPassRate = (tRunner.PassCount / tTotal) * 100
    
    Do $$$AssertEquals(tRunner.FailCount, 0, "No core vocabulary test failures")
    Do $$$AssertEquals(tPassRate, 100, "100% core vocabulary compliance")
    
    Quit $$$OK
}

/// Test overall compliance (required tests)
Method TestOverallCompliance() As %Status
{
    Set tRunner = ##class(Test.JSONSchema.TestSuite.TestSuiteRunner).%New()
    Set tSC = tRunner.RunAllTests()
    Do $$$AssertStatusOK(tSC, "Test suite ran successfully")
    
    // Log the report
    Set tReport = tRunner.GenerateReport()
    Write tReport
    
    // Assert high pass rate (allowing for documented edge cases)
    Set tTotal = tRunner.PassCount + tRunner.FailCount
    Set tPassRate = (tRunner.PassCount / tTotal) * 100
    
    Do $$$AssertTrue(tPassRate >= 99, "At least 99% compliance (documented edge cases allowed)")
    
    Quit $$$OK
}
```

### Test Execution Strategy

**Phase 1: Set Up Test Suite**
- Download JSON Schema Test Suite Draft 7 files
- Create directory structure
- Verify files are readable

**Phase 2: Implement Test Runner**
- Create TestSuiteRunner.cls
- Test with single file (type.json)
- Verify pass/fail counting

**Phase 3: Run Full Suite**
- Execute all Draft 7 tests
- Document any failures
- Fix validator bugs discovered
- Re-run until stable

**Phase 4: Create %UnitTest Wrapper**
- Create TestSuiteCompliance.cls
- Add category-level test methods
- Integrate with existing test run

**Expected Results:**
- Target: 100% required tests pass
- Optional format tests: Document status
- All 290+ existing unit tests still pass
- Full suite execution time: <60 seconds

### Test Coverage Matrix

| Category | Test Files | Tests (approx) | Target Pass Rate |
|----------|------------|----------------|------------------|
| Core Vocabulary | 15-20 files | ~200 tests | 100% |
| Combinators | 4 files | ~50 tests | 100% |
| Conditionals | 2 files | ~30 tests | 100% |
| References | 2 files | ~40 tests | 100% |
| Optional Format | 6-8 files | ~100 tests | Documented |
| **Total** | ~30 files | ~420 tests | 99%+ (excl. optional) |

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-12-04 | 1.1 | Story APPROVED - PO validation complete. Implementation Readiness Score: 9.0/10. GO decision. | PO Agent (Sarah) |
| 2025-12-04 | 1.0 | Initial story draft for JSON Schema Test Suite Compliance (Epic 2, Story 8) | SM Agent (Bob) |

---

## Dev Agent Record

### Agent Model Used

(To be filled by Dev Agent)

### Debug Log References

(To be filled by Dev Agent)

### Completion Notes List

(To be filled by Dev Agent)

### File List

(To be filled by Dev Agent)

---

## QA Results

(To be filled by QA Agent)
